---
layout: post
title: MCP Langgraph AI ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ì™€ LangChain MCP Adaptersì˜ FastMCP SSE ì˜ˆì œ
---
ìµœê·¼ AI ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•  ë•Œ, ë‹¤ì–‘í•œ ì™¸ë¶€ ë„êµ¬ë¥¼ ì†ì‰½ê²Œ ì—°ê²°í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆëŠ” **MCP (Modular Command Protocol)** ì•„í‚¤í…ì²˜ê°€ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤.

ğŸ§© MCPë€?

**MCP(Modular Command Protocol)**ëŠ” LLM ê¸°ë°˜ AI ì—ì´ì „íŠ¸ê°€ ë‹¤ì–‘í•œ ì™¸ë¶€ ë„êµ¬ë¥¼ ìœ ì—°í•˜ê²Œ í˜¸ì¶œí•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ **ë²”ìš© ì¸í„°í˜ì´ìŠ¤**ì…ë‹ˆë‹¤.

âœ”ï¸ MCPì˜ ì£¼ìš” íŠ¹ì§•

-   **ìœ ì—°í•œ í†µì‹ **: ë‹¤ì–‘í•œ í´ë¼ì´ì–¸íŠ¸/ì„œë²„ êµ¬ì„±ì—ì„œ ì‚¬ìš© ê°€ëŠ¥
-   **ë¹ ë¥¸ ë„êµ¬ ì—°ë™**: ë„êµ¬ë¥¼ ë°ì½”ë ˆì´í„° í•œ ì¤„ë¡œ ë…¸ì¶œ ê°€ëŠ¥
-   **ë¹ ë¥¸ ê°œë°œ ë° í”„ë¡œí† íƒ€ì´í•‘**ì— ìµœì 
-   **ë‚®ì€ ì§„ì… ì¥ë²½**: LangChain Adapter + FastMCPë¡œ ë°”ë¡œ ì‹œì‘ ê°€ëŠ¥




---

## ğŸ§± ì•„í‚¤í…ì²˜ êµ¬ì„± ê°œìš”

![image](https://github.com/user-attachments/assets/a5eed240-9134-4ee7-88c9-40d0b8401d6f)


MCP ì‹œìŠ¤í…œì€ í¬ê²Œ **3ê°€ì§€ ìš”ì†Œ**ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

1.  **MCP Host**
    -   ìœ ì €ê°€ ì‚¬ìš©í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤ (ì˜ˆ: ChatGPT, LangGraph, ì›¹ UI ë“±)
    -   MCP ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ì´ì ì‹¤í–‰ í™˜ê²½
2.  **MCP Client**
    -   ë„êµ¬ ëª©ë¡ì„ MCP ì„œë²„ì— ìš”ì²­í•˜ê³ , ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ëŠ” ì¤‘ê³„ì
    -   LangChain MCP Adapterë¡œ ì‰½ê²Œ êµ¬í˜„ ê°€ëŠ¥
3.  **MCP Server**
    -   ì‹¤ì œ ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ëŠ” ì„œë²„
    -   ë„êµ¬ë“¤ì€ í•¨ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì •ì˜ë˜ì–´ ìˆìœ¼ë©°, FastMCPë¡œ ê°„ë‹¨í•˜ê²Œ êµ¬ì„± ê°€ëŠ¥

---

## ğŸŒ SSE ë°©ì‹ì´ë€?

ìš°ë¦¬ëŠ” **SSE(Server-Sent Events)** ë°©ì‹ìœ¼ë¡œ MCP ì„œë²„ë¥¼ êµ¬ë™í•©ë‹ˆë‹¤. ì´ ë°©ì‹ì€ **HTTP ê¸°ë°˜ì˜ ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°**ì„ ì§€ì›í•˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ ì¥ì ì´ ìˆìŠµë‹ˆë‹¤:

-   **ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸**: ì„œë²„ì—ì„œ í´ë¼ì´ì–¸íŠ¸ë¡œ ì‹¤ì‹œê°„ ë°ì´í„° í‘¸ì‹œ
-   **HTTP ê¸°ë°˜**: ë°©í™”ë²½/í”„ë¡ì‹œ ìš°íšŒê°€ ì‰¬ì›Œ ìš´ì˜ í™˜ê²½ì— ì í•©
-   **ê²½ëŸ‰ í†µì‹ **: WebSocketë³´ë‹¤ ë‹¨ìˆœí•˜ê³  ë¹ ë¥´ê²Œ êµ¬ì„± ê°€ëŠ¥

---

## ğŸš€ FastMCPë¡œ MCP ì„œë²„ ë§Œë“¤ê¸°

Â [MCP SSE Remoteì‚¬ìš©í•˜ê¸°](https://hyeong9647.tistory.com/entry/MCP-Remote-SSE-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0)

ì´ì „ ê¸€ì“°ê¸°ë¥¼ ì°¸ì¡°í•´ì„œ MCPë¥¼ Remote SSEí™˜ê²½ì—ì„œ ë„ì–´ì„œ ì‚¬ìš©í•´ë³´ìÂ 

```
from typing import List
from mcp.server.fastmcp import FastMCP

# FastMCP ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° 'Weather' ë„êµ¬ ì¶”ê°€
mcp = FastMCP("Weather")

@mcp.tool()
async def get_weather(location: str) -> str:
    """ì§€ì •ëœ ìœ„ì¹˜ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ë°˜í™˜"""
    return f"It's always sunny in {location}"

# SSE ë°©ì‹ìœ¼ë¡œ MCP ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    mcp.run(transport="sse")
```

ìœ„ ì½”ë“œë¥¼ app.pyë¡œ ì €ì¥í•œ í›„, ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ SSE ì„œë²„ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆë‹¤.

## ğŸ¯Â ë­ì²´ì¸ ì½”ë“œ ì‹¤í–‰

ê°„ë‹¨í•œ create\_react\_agentë¥¼ ë§Œë“¤ì–´ì„œ ë˜‘ê°™ì€ ë™ì‘ì„ êµ¬í˜„í•˜ë ¤ê³  í•œë‹¤.

MCPëŠ” ì „ë¶€ ë¹„ë™ê¸°ë¥¼ ì‚¬ìš©í•´ì•¼ë˜ì„œ ë””ë²„ê·¸ê°€ ì‰½ì§€ ì•Šì§€ë§Œ ë‚˜ì˜ì§€ ì•Šê²Œ í•´ë³¼ë§Œí•˜ë‹¤.

```
import asyncio
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI

from langchain_mcp_adapters.client import SingleServerMCPClient


async def main():
    # OpenAI ëª¨ë¸ ì´ˆê¸°í™”
    model = ChatOpenAI(model="gpt-4o-mini", openai_api_key=api_key)

    # FastMCPì—ì„œ ì œê³µí•˜ëŠ” Weather ë„êµ¬ì— ì—°ê²° (SSE)
    async with SingleServerMCPClient(
        url="http://localhost:8000/sse",  # FastMCP ì„œë²„ í¬íŠ¸ì™€ ì¼ì¹˜í•´ì•¼ í•¨
        transport="sse"
    ) as client:
        tools = client.get_tools()
        print("Available tools:", tools)

        # MCP ë„êµ¬ë¡œ React Agent ìƒì„±
        agent = create_react_agent(model, tools)

        # ë©”ì‹œì§€ë¥¼ í†µí•œ ë„êµ¬ í˜¸ì¶œ
        response = await agent.ainvoke({"messages": "ì„œìš¸ì˜ ë‚ ì”¨ë¥¼ ì•Œë ¤ì¤˜"})
        print("Agent response:", response)

# ë¹„ë™ê¸° ì‹¤í–‰
asyncio.run(main())
```

## ğŸŒ ë­ê·¸ë˜í”„ ì½”ë“œ ì‹¤í–‰

ì—°ê²°í•˜ëŠ” ë°©ë²•ì€ ì–´ë µì§€ ì•Šë‹¤ ê¸°ì¡´ì˜ ì½”ë“œì—ì„œ toolë§Œ clientì—ì„œ ë°›ì•„ì™€ì„œ ì‚¬ìš©í•˜ë©´ ë˜‘ê°™ì´ ê¸°ì¡´ì½”ë“œë¥¼ ì‚¬ìš©í• ìˆ˜ ìˆë‹¤.Â 

```
import asyncio
from typing import Annotated
from typing_extensions import TypedDict

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition

from langchain_core.runnables import RunnableConfig
from langchain_openai import ChatOpenAI
from langchain_mcp_adapters.client import SingleServerMCPClient

# âœ… ìƒíƒœ ì •ì˜
class State(TypedDict):
    messages: Annotated[list, add_messages]

memory = MemorySaver()


# âœ… FastMCPìš© í´ë¼ì´ì–¸íŠ¸ ìƒì„± í•¨ìˆ˜
async def create_client():
    return SingleServerMCPClient(
        url="http://localhost:8000/sse",  # FastMCP ì„œë²„ í¬íŠ¸ì— ë§ì¶° ì„¤ì •
        transport="sse"
    )


# âœ… MCP Graph ìƒì„± í•¨ìˆ˜
def mcp_graph(client):
    tools = client.get_tools()
    print("ğŸ”§ MCP Tools:", tools)

    # LLM ì„¤ì •
    api_key = openai_api_key()
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, openai_api_key=api_key)
    llm_with_tools = llm.bind_tools(tools)

    # ì±—ë´‡ ë…¸ë“œ ì •ì˜
    def chatbot(state: State):
        return {"messages": [llm_with_tools.invoke(state["messages"])]}

    # ìƒíƒœ ê·¸ë˜í”„ ì •ì˜
    graph_builder = StateGraph(State)

    # ë…¸ë“œ êµ¬ì„±
    graph_builder.add_node("chatbot", chatbot)

    tool_node = ToolNode(tools=tools)
    graph_builder.add_node("tools", tool_node)

    graph_builder.add_conditional_edges("chatbot", tools_condition)
    graph_builder.add_edge("tools", "chatbot")

    # ì‹œì‘ê³¼ ì¢…ë£Œ ì •ì˜
    graph_builder.add_edge(START, "chatbot")
    graph_builder.add_edge("chatbot", END)

    # ê·¸ë˜í”„ ì»´íŒŒì¼
    return graph_builder.compile(checkpointer=memory)


# âœ… ë©”ì¸ í•¨ìˆ˜
async def main():
    config = RunnableConfig(
        recursion_limit=10,
        configurable={"thread_id": "1"},
        tags=["my-tag"]
    )

    async with await create_client() as client:
        agent = mcp_graph(client)
        response = await agent.ainvoke(
            {"messages": "ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜"},  # ë©”ì‹œì§€ë¥¼ MCP ë„êµ¬ì— ë§ê²Œ ì¡°ì •
            config=config
        )
        print("ğŸ“¨ Agent Response:", response)


# âœ… ì‹¤í–‰
asyncio.run(main())
```

ì•„ì‹œì•„ ë‚˜ê°€ ë‚˜ì˜ë‹¤
