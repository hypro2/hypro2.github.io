---
layout : post
title : 멀티모달 리뷰  moondream1 콜랩으로 실행하기
---

이번에 가져온 멀티모달은 moondream1 입니다. 이것도 phi와 SigLIP를 사용해서 파라미터를 줄이고, llava dataset으로 튜닝 완료된 데이터 입니다. 지난번의 리뷰한 imp와 유사한 모델입니다. 하지만 사용하는 방법에서 차이가 있고 튜닝 된 정도의 차이가 존재합니다. 

1.6B 매개변수 모델은 @vikhyatk가 SigLIP, Phi-1.5 및 LLaVa 훈련 데이터 세트를 사용하여 구축했습니다. 이 모델은 연구 목적으로만 공개되며, 상업적 사용은 허용되지 않습니다.

moondream1은 콜랩에서 사용할때 GPU를 8.5기가 정도 사용하고 있습니다.  imp의 8기가보다 조금더 많은 GPU 연산량을 보여줍니다. 해당 코드를 실행해보겠습니다.


![image](https://github.com/hypro2/hypro2.github.io/assets/84513149/f5c14d86-e816-40c1-a73b-e63f068155bd)


```
!pip install -U transformers
!pip install -q pillow accelerate einops timm

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from PIL import Image

torch.set_default_device("cuda")

model_id = "vikhyatk/moondream1"
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    trust_remote_code=True
)
tokenizer = AutoTokenizer.from_pretrained(
    model_id,
)

image = Image.open("/content/sdfsdfsdfdsf.jpg")

enc_image = model.encode_image(image) #이미지 인코딩

print(model.answer_question(enc_image, text, tokenizer)) # QA 실행
```
